---
title: "Code"
author: "Martin Kos√≠k"
date: "16 ledna 2019"
output: html_document
editor_options: 
  chunk_output_type: console
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(data.table)
theme_set(theme_light())
install.packages("keras")
library(keras)
install_keras()
library(lubridate)
library(caret)
```


```{r cars}
data <- fread("train_values.csv")
train_labels <- fread("train_labels.csv")
str(train_labels)
names(data)
data[, n = .N, by = phase]
data %>% 
  count( object_id, phase)
data[, timestamp := ymd_hms(timestamp)]
data[, turbidity_ntul  := max(0, return_flow) * return_turbidity]
data <- data[phase != 'final_rinse', ]

train <- data %>% 
  semi_join(data %>% 
              count(process_id, phase) %>% 
              sample_frac(0.8), by = c("process_id", "phase"))
 
test <- data %>% 
  anti_join(train, by = c("process_id", "phase")) 

str(data)
  
```

```{r}

```

```{r}
data <-
  data %>% 
  group_by(process_id, pipeline, object_id) %>% 
  select(-row_id) %>% 
  summarize_if(is.numeric, list(min = min, max = max,
                                mean = mean, sd = sd,
                                lambda = ~mean(.[ifelse(length(.)-5 < 1, length(.), length(.)-5):length(.)]))) %>% 
  ungroup() %>% 
  left_join(data %>% 
              count(process_id, phase) %>%
              spread(key = phase, value = n) %>% 
              replace(is.na(.), 0), by = "process_id") %>% 
  left_join(train_labels, by = "process_id") %>% 
  mutate(pipeline = as.factor(pipeline),
         object_id =as.factor(object_id), 
         process_id = as.factor(process_id)) %>% 
  select(-process_id)

gc()
fwrite(data, "data_summary.csv")

```

```{r}
data <- fread("data_summary.csv", colClasses = c(pipeline = "factor", object_id ="factor"))

inTrain <- createDataPartition(
  y = data$final_rinse_total_turbidity_liter,
  p = .80,
  list = FALSE)

train_set <- data[inTrain,]
test_set <- data[-inTrain,]

```

```{r}
MAPE <- function (data, lev = NULL, model = NULL) {
  ape <- abs(data$pred - data$obs) / map_dbl(data$obs, ~ max(abs(.x), 290000))
  out <- c(mean(ape))
  names(out) <- c("MAPE")
  out
} 

```

```{r}
MAPE_gen <- function (pred, obs) {
  ape <- abs(pred - obs)/ map_dbl(obs, ~ max(abs(.x), 290000))
  out <- c(mean(ape))
  names(out) <- c("MAPE")
  out
} 
```


```{r}
fitControl <- trainControl(method = "repeatedcv", number = 5, repeats = 3, summaryFunction = MAPE)
```


```{r GBM}
gbmGrid <-  expand.grid(interaction.depth = c(1, 5, 9), 
                        n.trees = (1:30)*50, 
                        shrinkage = 0.1,
                        n.minobsinnode = 20)

gbm_fit <- train(
  final_rinse_total_turbidity_liter ~ .,
  data = train_set,
  trControl = fitControl,
  method = "gbm",
  metric = "MAPE",
  verbose = FALSE, 
  maximize = FALSE)


MAPE_gen(predict(gbm_fit, newdata = test_set), test_set$final_rinse_total_turbidity_liter)
```



```{r random forest}
rfGrid <-  expand.grid(mtry = 85)

rf_fit <- train(
  final_rinse_total_turbidity_liter ~ .,
  data = train_set,
  trControl = fitControl,
  method = "rf",
  metric = "MAPE",
  verbose = FALSE, 
  maximize = FALSE, 
  tuneGrid = rfGrid)

MAPE_gen(predict(rf_fit, newdata = test_set), test_set$final_rinse_total_turbidity_liter)

```

```{r}
fitControl <- trainControl(method = "repeatedcv", number = 5, repeats = 1, summaryFunction = MAPE)
train_set 

xgb_Grid <-  expand.grid(nrounds = 50, max_depth = 5, eta = 0.4, gamma = 0,
                         colsample_bytree = 0.8, min_child_weight = 1, subsample = 1)

X_train = xgb.DMatrix(as.matrix(training %>% select(-PE)))
y_train = training$PE
X_test = xgb.DMatrix(as.matrix(testing %>% select(-PE)))
y_test = testing$PE

xgboost_fit <- train(
  final_rinse_total_turbidity_liter ~ .,
  data = train_set,
  trControl = fitControl,
  method = "xgbTree",
  metric = "MAPE",
  verbose = FALSE, 
  maximize = FALSE,
  tuneGrid = xgb_Grid)

plot(xgboost_fit)

# choose subsample 1..

MAPE_gen(predict(xgboost_fit, newdata = test_set), test_set$final_rinse_total_turbidity_liter)

 mean(abs(predict(xgboost_fit, newdata = test_set) - test_set$final_rinse_total_turbidity_liter)/
  map_dbl(predict(xgboost_fit, newdata = test_set), ~ max(abs(.x), 290000)))
  out <- c(mean(ape))
  names(out) <- c("MAPE")
  out
```
choose subsample 1.00, eta 0.3,  boosting iterations 60 and max tree depth 1
that is 
nrounds = 50, max_depth = 3, eta = 0.4, gamma = 0, colsample_bytree = 0.8, min_child_weight =
 1 and subsample = 1.

```{r}
data[process_id %in% 20001:20011, ] %>% 
  ggplot(aes(x = timestamp, y = turbidity_ntul, col = target_time_period)) + geom_line() + facet_wrap(~ process_id, scales = "free")
```

```{r}
x <- 4:10


last(x)
```

